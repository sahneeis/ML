{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class exercise 7: Deep Learning 1 (Part A)\n",
    "In this notebook we will see how to write efficient and numerically stable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Scale each feature to [-1, 1] range\n",
    "X = minmax_scale(X, feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of X : (569, 30)\n",
      "The shape of y : (569,)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# 检查 X 和 y 的形状\n",
    "print(\"The shapes of X :\", X.shape)  # 输出特征矩阵的形状 (n_samples, n_features)\n",
    "print(\"The shape of y :\", y.shape)  # 输出标签向量的形状 (n_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Logistic regression (two classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting:** Logistic regression (two classes)\n",
    "\n",
    "**Task:** Generate predictions for the entire dataset\n",
    "\n",
    "**Data:** $X \\in \\mathbb{R}^{n \\times d}$, $y \\in \\mathbb{R}^{n}$\n",
    "\n",
    "**Model:** $f(x) = \\sigma(w^T x + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]#值为30，样本特征为30\n",
    "w = np.random.normal(size=[n_features], scale=0.1)  # weight vector，正态分布所以分配权重给30个特征对应的权重，调整方差从1到0.1\n",
    "b = np.random.normal(size=[1])  # bias，给个标量，b~N（0，1）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [-0.03283724 -0.00453142  0.03874803 -0.0254831   0.01703173 -0.08540781\n",
      " -0.08210018 -0.01399902 -0.03677893  0.01313341  0.05320284  0.01832433\n",
      " -0.04683557  0.06853425 -0.03517877 -0.06111264  0.01527318  0.1097886\n",
      "  0.06336582  0.14272366  0.14136258  0.09721994 -0.20071091 -0.07773389\n",
      "  0.17203439  0.06824441  0.03175286 -0.12386361  0.0902873   0.02730797]\n",
      "b: [0.45633641]\n"
     ]
    }
   ],
   "source": [
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `sigmoid` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"Apply sigmoid to the input array.\"\"\"\n",
    "    # TODO\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work for any input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.5        0.73105858 0.88079708]\n",
      "[[0.5        0.73105858 0.88079708]\n",
      " [0.26894142 0.11920292 0.04742587]]\n"
     ]
    }
   ],
   "source": [
    "# input is a scalar\n",
    "print(sigmoid(0))\n",
    "\n",
    "# input is a vector\n",
    "print(sigmoid(np.array([0, 1, 2])))\n",
    "\n",
    "# input is a matrix\n",
    "print(sigmoid(np.array([[0, 1, 2], [-1, -2, -3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called **broadcasting**. The smaller array is \"broadcast\" across the larger array so that they have compatible shapes. Numpy does this automatically. Let's see how it works. (Also see [here](https://numpy.org/doc/stable/user/basics.broadcasting.html#).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# How does broadcasting work between a scalar and a vector?\n",
    "# TODO\n",
    "vector = np.array([1, 2, 3])\n",
    "scalar = 5\n",
    "\n",
    "# Broadcasting in action\n",
    "result = vector + scalar\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "Scalar: 3\n",
      "Result of broadcasting:\n",
      " [[4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# How does broadcasting work between a scalar and a matrix?\n",
    "# TODO\n",
    "# Define a scalar and a matrix\n",
    "scalar = 3\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "\n",
    "# Perform broadcasting addition\n",
    "result = matrix + scalar\n",
    "\n",
    "# Print results\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "print(\"Scalar:\", scalar)\n",
    "print(\"Result of broadcasting:\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 22 33]\n",
      " [14 25 36]]\n",
      "[[11 12 13]\n",
      " [24 25 26]]\n"
     ]
    }
   ],
   "source": [
    "# How does broadcasting work between a vector and a matrix?\n",
    "# TODO\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "row_vector = np.array([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "result1 = matrix + row_vector  # Broadcasting\n",
    "print(result1)\n",
    "column_vector = np.array([[10],\n",
    "                          [20]])  # Shape: (2, 1)\n",
    "\n",
    "result2 = matrix + column_vector  # Broadcasting\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad - for loops\n",
    "\n",
    "Generate predictions with a logistic regression model using a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_loop(X, w, b):\n",
    "    \"\"\"Generate predictions with a logistic regression model using a for-loop.\n",
    "\n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        w: weights vector, shape (D)\n",
    "        b: bias term, shape (1)\n",
    "\n",
    "    Returns:\n",
    "        y: probabilities of the positive class, shape (N)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    N, D = X.shape  # Number of samples (N) and features (D)\n",
    "    y = np.zeros(N)  # Initialize the output probabilities\n",
    "\n",
    "    for i in range(N):\n",
    "        # Calculate z = x_i * w + b for the i-th sample\n",
    "        z = np.dot(X[i], w) + b\n",
    "        # Apply the sigmoid function and ensure it's a scalar\n",
    "        y[i] = sigmoid(z).item()  # .item() ensures the result is a scalar\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good - vectorization\n",
    "\n",
    "Generate predictions with a logistic regression model using vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_vectorized(X, w, b):\n",
    "    \"\"\"Generate predictions with a logistic regression model using vectorized operations.\n",
    "\n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        w: weights vector, shape (D)\n",
    "        b: bias term, shape (1)\n",
    "\n",
    "    Returns:\n",
    "        y: probabilies of the positive class, shape (N)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Compute the linear model z = X @ w + b\n",
    "    z = np.dot(X, w) + b  # X @ w is the same as np.dot(X, w)\n",
    "    \n",
    "    # Apply the sigmoid function to z to get probabilities\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that both variants produce the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_loop = predict_for_loop(X, w, b)\n",
    "results_vectorized = predict_vectorized(X, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of results_for_loop: (569,)\n",
      "Shape of results_vectorized: (569,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# Check the shape of the results\n",
    "print(f\"Shape of results_for_loop: {results_for_loop.shape}\")\n",
    "print(f\"Shape of results_vectorized: {results_vectorized.shape}\")\n",
    "\n",
    "# Check if both results are numerically close\n",
    "# if np.allclose(results_for_loop, results_vectorized):这是比较close，要看相同用=\n",
    "#     print(\"Both methods produce the same result!\")\n",
    "# else:\n",
    "#     print(\"The results are different.\")\n",
    "np.all(results_for_loop == results_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the norm of the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the difference: 6.77599954797753e-16\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Compute the difference between the two results\n",
    "difference = results_for_loop - results_vectorized\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference\n",
    "norm_difference = np.linalg.norm(difference)\n",
    "\n",
    "# Print the result\n",
    "print(\"Norm of the difference:\", norm_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are they close enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both methods produce the same result!\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#depends on the thereholds that we have already set, such as 1e-6 or 1e-10\n",
    "if np.allclose(results_for_loop, results_vectorized):#这是比较close，要看相同用=\n",
    "    print(\"Both methods produce the same result!\")\n",
    "else:\n",
    "    print(\"The results are different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the runtime of two variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 ms ± 26 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predict_for_loop(X, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.79 μs ± 70.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predict_vectorized(X, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. K-nearest neighbors\n",
    "A more complicated task: compute the matrix of pairwise distances.\n",
    "\n",
    "Given a data matrix `X` of size `[N, D]`, compute the matrix `dist` of pairwise distances of size `[N, N]`, where `dist[i, j] = l2_distance(X[i], X[j])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 distance is:\n",
    "\n",
    "$$\n",
    "d_2(a, b) = \\sqrt{\\sum_{i=1}^d (a_i - b_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad - for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance(x, y):\n",
    "    \"\"\"Compute Euclidean distance between two vectors.\"\"\"\n",
    "    # TODO\n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_for_loop(X):\n",
    "    \"\"\"Compute pairwise distances between all instances (for loop version).\n",
    "\n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "\n",
    "    Returns:\n",
    "        dist: matrix of pairwise distances, shape (N, N)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    N = X.shape[0]  # Number of rows\n",
    "    dist = np.zeros((N, N))  # Initialize the distance matrix\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            dist[i, j] = l2_distance(X[i], X[j])\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         2.99965852 1.91448055 ... 3.46242403 2.02714709 5.10607491]\n",
      " [2.99965852 0.         1.50824977 ... 1.49479679 3.33795732 3.28948876]\n",
      " [1.91448055 1.50824977 0.         ... 1.89129137 2.10557371 3.96949079]\n",
      " ...\n",
      " [3.46242403 1.49479679 1.89129137 ... 0.         3.27879383 2.51965124]\n",
      " [2.02714709 3.33795732 2.10557371 ... 3.27879383 0.         5.32401844]\n",
      " [5.10607491 3.28948876 3.96949079 ... 2.51965124 5.32401844 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# compute pairwise distances using for loops\n",
    "dist1 = distances_for_loop(X)\n",
    "print(dist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good - vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we compute all the distances in a vectorized way?\n",
    "\n",
    "Start with a simpler example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(5, dtype=np.float64)#是个1D列向量\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `numpy` broadcasting to compute the matrix of pairwise distances in a vectorized way. We achieve this by adding a new axis to `x` using `np.newaxis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "x[:,None].repeat(x.shape[0],axis=1)\n",
    "#x[:,None]这个操作将1D（5，）变到2D（5，1）\n",
    "#axis=1表示再列的维度上面的重复。是按照行进行操作，首先把向量看成一列，再复制到五列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "x[None,:].repeat(x.shape[0],axis=0)\n",
    "#根据上面这个就是1D（5，）变到2D（1，5）再按照对行的维度上进行重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -2., -3., -4.],\n",
       "       [ 1.,  0., -1., -2., -3.],\n",
       "       [ 2.,  1.,  0., -1., -2.],\n",
       "       [ 3.,  2.,  1.,  0., -1.],\n",
       "       [ 4.,  3.,  2.,  1.,  0.]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "x[:,None]-x[None,:]#对应相减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result can be achieved using `None` indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "np.sum(np.square(x[:,None]-x[None,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_vectorized(X):\n",
    "    \"\"\"Compute pairwise distances between all instances (vectorized version).\n",
    "\n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "\n",
    "    Returns:\n",
    "        dist: matrix of pairwise distances, shape (N, N)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(np.sum((X[:,None]-X[None,:])**2,axis=-1))\n",
    "    #（N，1，D）-（1，N，D）=（N，N，D）。np.sum(..., axis=-1)沿着最后一个维度，特征D求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pairwise distances using vectorized operations\n",
    "dist2 = distances_vectorized(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that both variants produce the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dist1, dist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best - library function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "dist3 = cdist(X, X)\n",
    "dist4 = squareform(pdist(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that both variants produce the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use np.allclose to compare\n",
    "np.allclose(dist2, dist3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 s ± 10.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "distances_for_loop(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 ms ± 141 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "distances_vectorized(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.93 ms ± 94 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cdist(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.41 ms ± 62.5 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "squareform(pdist(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons:\n",
    "1. For-loops are extremely slow! Avoid them whenever possible.\n",
    "2. A better alternative - use matrix operations & broadcasting\n",
    "3. An even better alternative - use library functions (if they are available).\n",
    "4. Implementations with for-loops can be useful for debugging vectorized code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Numerical stability\n",
    "Typically, GPUs use single precision (32bit) floating point numbers (in some cases even half precision / 16bit). This significantly speeds ups the computations, but also makes numerical issues a lot more likely. \n",
    "Because of this we always have to be extremely careful to implement our code in a numerically stable way.\n",
    "\n",
    "Most commonly, numerical issues occur when dealing with `log` and `exp` functions (e.g. when computing cross-entropy of a categorical distribution) and `sqrt` for values close to zero (e.g. when computing standard deviations or normalizing the $L_2$ norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(finfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64),\n",
       " finfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32),\n",
       " finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(np.float64), np.finfo(np.float32), np.finfo(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Avoiding numerical overflow (exploding `exp`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function $f : \\mathbb{R}^D \\to \\Delta^{D - 1}$ converts a vector $\\mathbf{x} \\in \\mathbb{R}^D$ into a vector of probabilities.\n",
    "\n",
    "$$f(\\mathbf{x})_j = \\frac{\\exp(x_j)}{\\sum_{d=1}^{D} \\exp(x_d)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_unstable(logits):\n",
    "    # TODO\n",
    "    exp= np.exp(logits)\n",
    "    return exp/np.sum(exp,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the softmax function to the following vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0.0, 4.0, 5).astype(np.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01165623, 0.03168492, 0.08612854, 0.23412167, 0.6364086 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_unstable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply it to the following vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50., 60., 70., 80., 90.], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(50.0, 90.0, 5).astype(np.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01165623, 0.03168492, 0.08612854, 0.23412167, 0.6364086 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_unstable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to avoid the explosion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift the values by a constant $C$.\n",
    "\n",
    "$$f(\\mathbf{x})_j = \\frac{\\exp(x_j - C)}{\\sum_{d=1}^{D} \\exp(x_d - C)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_stable(logits):\n",
    "    \"\"\"Compute softmax values for each sets of scores in logits.\"\"\"\n",
    "    # TODO\n",
    "    logits_shifted= logits-np.max(logits,axis=0)\n",
    "    denominator = np.sum(np.exp(logits_shifted),axis=0)\n",
    "    return np.exp(logits_shifted)/denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(50.0, 90.0, 5).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.24816138e-18, 9.35719813e-14, 2.06106005e-09, 4.53978686e-05,\n",
       "       9.99954600e-01])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_unstable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Working in the log-space / simplifying the expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary cross entropy (BCE) loss for a logistic regression model (corresponds to negative log-likelihood of a Bernoulli model)\n",
    "\n",
    "$$\\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}, b) = -\\sum_{i=1}^{N} y_i \\log \\sigma(\\mathbf{w}^T \\mathbf{x}_i + b) + (1 - y_i) \\log (1 - \\sigma(\\mathbf{w}^T \\mathbf{x}_i + b))$$\n",
    "\n",
    "\n",
    "Implement the BCE computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    # TODO\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "\n",
    "def binary_cross_entropy_unstable(scores, labels):\n",
    "    \"\"\"Compute binary cross-entropy loss for one sample.\"\"\"\n",
    "    # TODO\n",
    "    return -labels * np.log(sigmoid(scores))-(1-labels)* np.log(1-sigmoid(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZHIYU_ZHAO\\AppData\\Local\\Temp\\ipykernel_20156\\2240649128.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  return -labels * np.log(sigmoid(scores))-(1-labels)* np.log(1-sigmoid(scores))\n",
      "C:\\Users\\ZHIYU_ZHAO\\AppData\\Local\\Temp\\ipykernel_20156\\2240649128.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -labels * np.log(sigmoid(scores))-(1-labels)* np.log(1-sigmoid(scores))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[20.0, 20.0]])  # [1, 2]\n",
    "w = np.array([[1.0, 1.0]])  # [1, 2]\n",
    "y = np.array([1.0])  # [1,]\n",
    "\n",
    "# 1. compute logits\n",
    "# TODO\n",
    "scores = np.dot(x,w.T)\n",
    "# 2. compute loss\n",
    "# TODO\n",
    "binary_cross_entropy_unstable (scores,y)#溢出了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to simplify the BCE loss as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binary_cross_entropy_stable(scores, labels):\n",
    "    # TODO\n",
    "    return np.log(1+np.exp(scores)) - labels * scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. compute logits\n",
    "# TODO\n",
    "scores = np.dot(x,w.T)\n",
    "# 2. compute loss\n",
    "# TODO\n",
    "binary_cross_entropy_stable (scores,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Loss of numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the log sigmoid function \n",
    "\n",
    "$$f(x) = \\log \\sigma(x) = \\log \\left(\\frac{1}{1 + \\exp(-x)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sigmoid_unstable(x):\n",
    "    # TODO\n",
    "    return np.log(1/(1+np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`float32` has much lower \"resolution\" than `float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30.],\n",
       "       dtype=float32),\n",
       " array([-6.9314718e-01, -4.8587341e-02, -2.4756414e-03, -1.2338923e-04,\n",
       "        -6.1989022e-06, -3.5762793e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float32)\n",
    "x, log_sigmoid_unstable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.93147181e-01, -4.85873516e-02, -2.47568514e-03, -1.23402190e-04,\n",
       "       -6.14419348e-06, -3.05902274e-07, -1.52299796e-08, -7.58256125e-10,\n",
       "       -3.77513576e-11, -1.87960758e-12, -9.34807787e-14])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float64)\n",
    "log_sigmoid_unstable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the log-sigmoid function in a numerically stable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sigmoid_stable(x):\n",
    "    # TODO\n",
    "    return -np.log1p(np.exp(-x))#log1p dengyushangmiande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.9314718e-01, -4.8587352e-02, -2.4756852e-03, -1.2340219e-04,\n",
       "       -6.1441938e-06, -3.0590229e-07, -1.5229981e-08, -7.5825601e-10,\n",
       "       -3.7751344e-11, -1.8795287e-12, -9.3576229e-14], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float32)\n",
    "log_sigmoid_stable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant functions: `np.log1p`, `np.expm1`, `scipy.special.logsumexp`, `scipy.special.softmax` -- these are also implemented in all major deep learning frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons:\n",
    "1. Be especially careful when working with `log` and `exp` functions in **single precision** floating point arithmetics\n",
    "2. Work in the log-space when possible\n",
    "3. Use numerically stable library functions when available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
