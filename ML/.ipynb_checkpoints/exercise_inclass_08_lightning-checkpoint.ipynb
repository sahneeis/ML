{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class exercise 8: Converting your PyTorch code to PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [Lightning in 15 minutes](https://lightning.ai/docs/pytorch/stable/starter/introduction.html) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will convert the code from the previous tutorial to PyTorch Lightning. This will allow us to reduce the amount of boilerplate code we need to write, and also make it easier to train our model on multiple GPUs or even TPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Lightning is a lightweight **wrapper** for **organizing** your PyTorch code. It's **not a high-level framework**, so you still have to write PyTorch code, but it handles a lot of the details for you. It's especially useful for **standardizing** training loops, logging metrics, and saving checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install PyTorch Lightning and import the relevant classes and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from typeguard import typechecked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we report here some code from the previous tutorial for reference purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: we re-define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we re-define the dataset and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_dataloaders():\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None()  # TODO\n",
    "print(model)\n",
    "train_dataset, val_dataset, test_dataset = get_datasets()  # TODO\n",
    "dataloaders = instantiate_dataloaders()  # TODO\n",
    "print(next(iter(dataloaders[\"train\"]))[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally re-define the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch():\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE = 3\n",
    "\n",
    "# data\n",
    "NUM_WORKERS = 3\n",
    "\n",
    "# optimizer\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# model\n",
    "NUM_LAYERS = 3\n",
    "NUM_CHANNELS = 32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: replace `nn.Module` with `LightningModule`\n",
    "\n",
    "- 1.1: Model architecture goes in the `__init__` method\n",
    "- 1.2: Prediction/inference logic goes in the `forward` hook\n",
    "- 1.3: Optimizers go in the `configure_optimizers` hook\n",
    "- 1.4: Training logic goes in the `training_step` hook\n",
    "- 1.5: Validation logic goes in the `validation_step` hook\n",
    "- 1.6: Test logic goes in the `test_step` hook\n",
    "- 1.7: Remove any `cuda()` or `to(device)` calls\n",
    "- 1.8: Instantiate the `LightningModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLit(pl.LightningModule):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.8: Create an instance of the `LitModule` class\n",
    "lit_module = CNNLit()  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: replace the training loop with a `Trainer` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `LightningModule` is defined, we can train it using a `Trainer`.\n",
    "\n",
    "- 1: Instantiate the `Trainer`\n",
    "- 2: Call `trainer.fit(model, train_dataloader, val_dataloader)` to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = None  # TODO\n",
    "\n",
    "# Call `trainer.fit()` to train the model\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call `trainer.test()` to test the model\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: replace the dataset and dataloaders with `LightningDataModule`\n",
    "\n",
    "- 1: Move the dataset and dataloaders into a `LightningDataModule`\n",
    "- 2: Instantiate the `LightningDataModule`\n",
    "- 3: Pass the `LightningDataModule` to the `Trainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `LightningDataModule` encapsulates the five steps involved in data processing in PyTorch:\n",
    "- 2.1: Download / tokenize / process.\n",
    "- 2.2: Clean and (maybe) save to disk.\n",
    "- 2.3: Load inside Dataset.\n",
    "- 2.4: Apply transforms (rotate, tokenize, etcâ€¦).\n",
    "- 2.5: Wrap inside a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MNISTDataModule()  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLit()  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer()  # TODO\n",
    "\n",
    "# Fit\n",
    "# TODO\n",
    "\n",
    "# Test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we were only able to log the loss. However, Lightning allows us to have much more control over logging. For example, we can log the loss and accuracy after each epoch, and also log the loss and accuracy after each batch. We can even log images, audio, text, and arbitrary objects.\n",
    "\n",
    "We will be using [TorchMetrics](https://torchmetrics.readthedocs.io/en/latest/index.html) to compute metrics. TorchMetrics is a collection of metrics for PyTorch. It allows us to avoid writing boilerplate code for computing metrics like accuracy, precision, recall, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class CNNLit(pl.LightningModule):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(SEED)  # reproducibility\n",
    "\n",
    "model = CNNLit()  # TODO\n",
    "datamodule = MNISTDataModule()  # TODO\n",
    "\n",
    "trainer = pl.Trainer()  # TODO\n",
    "\n",
    "# Fit\n",
    "# TODO\n",
    "\n",
    "# Test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing metrics\n",
    "\n",
    "We can visualize the metrics logged by Lightning using [TensorBoard](https://www.tensorflow.org/tensorboard) or [Weights & Biases](https://wandb.ai/site). We will be using TensorBoard in this tutorial. To install TensorBoard, you can use `pip install tensorboard`. To start TensorBoard, you can use the following command:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir lightning_logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLit(pl.LightningModule):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(SEED)  # reproducibility\n",
    "\n",
    "model = CNNLit()  # TODO\n",
    "datamodule = MNISTDataModule()  # TODO\n",
    "\n",
    "logger = None  # TODO\n",
    "\n",
    "trainer = pl.Trainer()  # TODO\n",
    "\n",
    "# Fit\n",
    "# TODO\n",
    "\n",
    "# Test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "\n",
    "Lightning automatically saves checkpoints of your model at the end of every epoch. If training is interrupted, you can resume from the last saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "# TODO\n",
    "\n",
    "# Test the best model\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gsl_3.10.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
