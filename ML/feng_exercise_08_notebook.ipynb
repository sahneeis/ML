{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9493,
     "status": "ok",
     "timestamp": 1734447257358,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "8A8QG-4YscJy"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0luGYfdVscJ1"
   },
   "source": [
    "# PyTorch\n",
    "In this notebook you will gain some hands-on experience with [PyTorch](https://pytorch.org/), one of the major frameworks for deep learning. To install PyTorch. follow [the official installation instructions](https://pytorch.org/get-started/locally/). Make sure that you select the correct OS & select the version with CUDA if your computer supports it.\n",
    "If you do not have an Nvidia GPU, you can install the CPU version by setting `CUDA` to `None`.\n",
    "However, in this case we recommend using [Google Colab](https://colab.research.google.com/).\n",
    "Make sure that you enable GPU acceleration in `Runtime > Change runtime type`.\n",
    "\n",
    "You will start by re-implementing some common features of deep neural networks (dropout and batch normalization) and then implement a very popular modern architecture for image classification (ResNet) and improve its training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbaBdP6LscJ3"
   },
   "source": [
    "# 1. Dropout\n",
    "Dropout is a form of regularization for neural networks. It works by randomly setting activations (values) to 0, each one with equal probability `p`. The values are then scaled by a factor $\\frac{1}{1-p}$ to conserve their mean.\n",
    "\n",
    "Dropout effectively trains a pseudo-ensemble of models with stochastic gradient descent. During evaluation we want to use the full ensemble and therefore have to turn off dropout. Use `self.training` to check if the model is in training or evaluation mode.\n",
    "\n",
    "Do not use any dropout implementation from PyTorch for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1734447260722,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "iOToMY7tscJ4"
   },
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Dropout, as discussed in the lecture and described here:\n",
    "    https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout\n",
    "\n",
    "    Args:\n",
    "        p: float, dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        The module's forward pass.\n",
    "        This has to be implemented for every PyTorch module.\n",
    "        PyTorch then automatically generates the backward pass\n",
    "        by dynamically generating the computational graph during\n",
    "        execution.\n",
    "\n",
    "        Args:\n",
    "            input: PyTorch tensor, arbitrary shape\n",
    "\n",
    "        Returns:\n",
    "            PyTorch tensor, same shape as input\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Set values randomly to 0.\n",
    "        if self.training:  # Apply dropout only during training\n",
    "            # Create a mask of the same shape as input with values 0 or 1\n",
    "            mask = (torch.rand_like(input) > self.p).float()\n",
    "            # Scale the remaining values by 1 / (1-p)\n",
    "            return input * mask / (1 - self.p)\n",
    "        else:\n",
    "            # During evaluation, return input unchanged\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1734447263794,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "VRqo579EscJ4"
   },
   "outputs": [],
   "source": [
    "# Test dropout\n",
    "test = torch.rand(10_000)\n",
    "dropout = Dropout(0.2)\n",
    "test_dropped = dropout(test)\n",
    "\n",
    "# These assertions can in principle fail due to bad luck, but\n",
    "# if implemented correctly they should almost always succeed.\n",
    "assert np.isclose(test_dropped.mean().item(), test.mean().item(), atol=1e-2)\n",
    "assert np.isclose((test_dropped > 0).float().mean().item(), 0.8, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja4mq-WascJ5"
   },
   "source": [
    "# 2. Batch normalization\n",
    "Batch normalization is a trick use to smoothen the loss landscape and improve training. It is defined as the function\n",
    "$$y = \\frac{x - \\mu_x}{\\sigma_x + \\epsilon} \\cdot \\gamma + \\beta$$,\n",
    "where $\\gamma$ and $\\beta$ and learnable parameters and $\\epsilon$ is a some small number to avoid dividing by zero. The Statistics $\\mu_x$ and $\\sigma_x$ are taken separately for each feature. In a CNN this means averaging over the batch and all pixels.\n",
    "\n",
    "Do not use any batch normalization implementation from PyTorch for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1734447267172,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "21IslcdsscJ5"
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Batch normalization, as discussed in the lecture and similar to\n",
    "    https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d\n",
    "\n",
    "    Only uses batch statistics (no running mean for evaluation).\n",
    "    Batch statistics are calculated for a single dimension.\n",
    "    Gamma is initialized as 1, beta as 0.\n",
    "\n",
    "    Args:\n",
    "        num_features: Number of features to calculate batch statistics for.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Initialize the required parameters\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Batch normalization over the dimension C of (N, C, L).\n",
    "\n",
    "        Args:\n",
    "            input: PyTorch tensor, shape [N, C, L]\n",
    "\n",
    "        Return:\n",
    "            PyTorch tensor, same shape as input\n",
    "        \"\"\"\n",
    "        eps = 1e-5\n",
    "\n",
    "        # TODO: Implement the required transformation\n",
    "        # Calculate mean and variance along the (N, Channel skip, L) dimensions, keep dimension for broadcasting\n",
    "        mean = input.mean(dim=(0, 2), keepdim=True)  # Mean over batch and length\n",
    "        var = input.var(dim=(0, 2), unbiased=False, keepdim=True)  # Variance over batch and length\n",
    "\n",
    "        # Normalize the input\n",
    "        input_normalized = (input - mean) / np.sqrt(var + eps)\n",
    "\n",
    "        # Scale and shift using learnable parameters gamma and beta\n",
    "        output = self.gamma.view(1, -1, 1) * input_normalized + self.beta.view(1, -1, 1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1734447271072,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "xr4R_e4escJ5"
   },
   "outputs": [],
   "source": [
    "# Tests the batch normalization implementation\n",
    "torch.random.manual_seed(42)\n",
    "test = torch.randn(8, 2, 4)\n",
    "\n",
    "b1 = BatchNorm(2)\n",
    "test_b1 = b1(test)\n",
    "\n",
    "b2 = nn.BatchNorm1d(2, affine=False, track_running_stats=False)\n",
    "test_b2 = b2(test)\n",
    "\n",
    "assert torch.allclose(test_b1, test_b2, rtol=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8yF011IscJ6"
   },
   "source": [
    "# 3. ResNet\n",
    "ResNet is the models that first introduced residual connections (a form of skip connections). It is a rather simple, but successful and very popular architecture. In this part of the exercise we will re-implement it step by step.\n",
    "\n",
    "Note that there is also an [improved version of ResNet](https://arxiv.org/abs/1603.05027) with optimized residual blocks. Here we will implement the [original version](https://arxiv.org/abs/1512.03385) for CIFAR-10. Your dropout and batchnorm implementations won't help you here. Just use PyTorch's own layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khm5f6_fscJ6"
   },
   "source": [
    "This is just a convenience function to make e.g. `nn.Sequential` more flexible. It is e.g. useful in combination with `x.squeeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1734447274453,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "JTvwYkLNscJ6"
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZlp1Y-9scJ7"
   },
   "source": [
    "We begin by implementing the residual blocks. The block is illustrated by this sketch:\n",
    "\n",
    "![Residual connection](img/residual_connection.png)\n",
    "\n",
    "Note that we use 'SAME' padding, no bias, and batch normalization after each convolution. You do not need `nn.Sequential` here. The skip connection is already implemented as `self.skip`. It can handle different strides and increases in the number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1734447277476,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "3zdCMH9iscJ7"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The residual block used by ResNet.\n",
    "\n",
    "    Args:\n",
    "        in_channels: The number of channels (feature maps) of the incoming embedding\n",
    "        out_channels: The number of channels after the first convolution\n",
    "        stride: Stride size of the first convolution, used for downsampling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        if stride > 1 or in_channels != out_channels:\n",
    "            # Add strides in the skip connection and zeros for the new channels.\n",
    "            self.skip = Lambda(lambda x: F.pad(x[:, :, ::stride, ::stride],\n",
    "                                               (0, 0, 0, 0, 0, out_channels - in_channels),\n",
    "                                               mode=\"constant\", value=0))\n",
    "        else:\n",
    "            self.skip = nn.Sequential()\n",
    "\n",
    "        # TODO: Initialize the required layers\n",
    "        # Initialize the required layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)  # Batch normalization after the first convolution\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)  # Batch normalization after the second convolution\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: Execute the required layers and functions\n",
    "        # Save the skip connection\n",
    "        skip_connection = self.skip(input)\n",
    "\n",
    "        # Apply first convolution, batch normalization, and ReLU activation\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply second convolution and batch normalization\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Add skip connection and apply ReLU activation\n",
    "        x += skip_connection\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfTOAI65scJ7"
   },
   "source": [
    "Next we implement a stack of residual blocks for convenience. The first layer in the block is the one changing the number of channels and downsampling. You can use `nn.ModuleList` to use a list of child modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1734447281170,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "7qWOi7VgscJ7"
   },
   "outputs": [],
   "source": [
    "class ResidualStack(nn.Module):\n",
    "    \"\"\"\n",
    "    A stack of residual blocks.\n",
    "\n",
    "    Args:\n",
    "        in_channels: The number of channels (feature maps) of the incoming embedding\n",
    "        out_channels: The number of channels after the first layer\n",
    "        stride: Stride size of the first layer, used for downsampling\n",
    "        num_blocks: Number of residual blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, num_blocks):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Initialize the required layers (blocks)\n",
    "        # The first residual block handles channel change and downsampling\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(ResidualBlock(in_channels, out_channels, stride=stride))\n",
    "\n",
    "        # Subsequent blocks maintain the same number of channels and no downsampling (stride=1)\n",
    "        for _ in range(1, num_blocks):\n",
    "            self.blocks.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: Execute the layers (blocks)\n",
    "        x = input\n",
    "        for block in self.blocks:\n",
    "            x = block(x)  # Apply each residual block sequentially\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7GBAGJmscJ8"
   },
   "source": [
    "Now we are finally ready to implement the full model! To do this, use the `nn.Sequential` API and carefully read the following paragraph from the paper (Fig. 3 is not important):\n",
    "\n",
    "![ResNet CIFAR10 description](img/resnet_cifar10_description.png)\n",
    "\n",
    "Note that a convolution layer is always convolution + batch norm + activation (ReLU), that each ResidualBlock contains 2 layers, and that you might have to `squeeze` the embedding before the dense (fully-connected) layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1734447284699,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "Iofu3yJIscJ8",
    "outputId": "cc1a3a22-b27b-401f-9eb0-354311154e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "#n = 5\n",
    "#num_classes = 10\n",
    "\n",
    "# TODO: Implement ResNet via nn.Sequential\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet for CIFAR10.\n",
    "    \"\"\"\n",
    "    def __init__(self, n, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),  # Input channels changed to 3\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            ResidualStack(16, 16, stride=1, num_blocks=n),\n",
    "            ResidualStack(16, 32, stride=2, num_blocks=n),\n",
    "            ResidualStack(32, 64, stride=2, num_blocks=n),\n",
    "            nn.AvgPool2d(kernel_size=8),  # Global average pooling\n",
    "            Lambda(lambda x: x.squeeze()),  # Squeeze before the dense layer\n",
    "            nn.Linear(64, num_classes)  # Dense layer with num_classes outputs\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "n = 5\n",
    "num_classes = 10\n",
    "\n",
    "# Instantiate the model\n",
    "resnet = ResNet(n, num_classes)  # Using the ResNet class\n",
    "\n",
    "# Test input\n",
    "x = torch.randn(8, 3, 32, 32)\n",
    "output = resnet(x)\n",
    "\n",
    "print(output.shape)  # Output should be (8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF7gYVRQscJ8"
   },
   "source": [
    "Next we need to initialize the weights of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1734447288141,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "sViAzTEnscJ8"
   },
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        nn.init.constant_(module.weight, 1)\n",
    "        nn.init.constant_(module.bias, 0)\n",
    "\n",
    "resnet.apply(initialize_weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljxqTcnYscJ8"
   },
   "source": [
    "# 4. Training\n",
    "So now we have a shiny new model, but that doesn't really help when we can't train it. So that's what we do next.\n",
    "\n",
    "First we need to load the data. Note that we split the official training data into train and validation sets, because you must not look at the test set until you are completely done developing your model and report the final results. Some people don't do this properly, but you should not copy other people's bad habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1734447291232,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "GiPYcIJFscJ8"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Subset(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"\n",
    "    Get a subset of the CIFAR10 dataset, according to the passed indices.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, idx=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        if idx is None:\n",
    "            return\n",
    "\n",
    "        self.data = self.data[idx]\n",
    "        targets_np = np.array(self.targets)\n",
    "        self.targets = targets_np[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdBj9MDYscJ9"
   },
   "source": [
    "We next define transformations that change the images into PyTorch tensors, standardize the values according to the precomputed mean and standard deviation, and provide data augmentation for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1734447294920,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "bmcYxSsCscJ9"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22110,
     "status": "ok",
     "timestamp": 1734447320316,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "Sx-0tmXlscJ9",
    "outputId": "a9ddb04a-c80c-4d45-ba1d-45ad58d7382b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ntrain = 45_000\n",
    "train_set = CIFAR10Subset(root='./data', train=True, idx=range(ntrain),\n",
    "                          download=True, transform=transform_train)\n",
    "val_set = CIFAR10Subset(root='./data', train=True, idx=range(ntrain, 50_000),\n",
    "                        download=True, transform=transform_eval)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1734447325028,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "Tk0O-q_BscJ9"
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(train_set, batch_size=128,\n",
    "                                                   shuffle=True, num_workers=0,\n",
    "                                                   pin_memory=True)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(val_set, batch_size=128,\n",
    "                                                 shuffle=False, num_workers=0,\n",
    "                                                 pin_memory=True)\n",
    "dataloaders['test'] = torch.utils.data.DataLoader(test_set, batch_size=128,\n",
    "                                                  shuffle=False, num_workers=0,\n",
    "                                                  pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eglhvE3mscJ-"
   },
   "source": [
    "Next we push the model to our GPU (if there is one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1734447328289,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "ECyWPXOHscJ-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "resnet.to(device);\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # 检查 CUDA 是否可用\n",
    "print(torch.cuda.get_device_name(0))  # 显示 GPU 名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnST24TQscJ-"
   },
   "source": [
    "Next we define a helper method that does one epoch of training or evaluation. We have only defined training here, so you need to implement the necessary changes for evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1734447918336,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "92jzP-tMscJ-"
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, dataloader, train):\n",
    "    \"\"\"\n",
    "    Run one epoch of training or evaluation.\n",
    "\n",
    "    Args:\n",
    "        model: The model used for prediction\n",
    "        optimizer: Optimization algorithm for the model\n",
    "        dataloader: Dataloader providing the data to run our model on\n",
    "        train: Whether this epoch is used for training or evaluation\n",
    "\n",
    "    Returns:\n",
    "        Loss and accuracy in this epoch.\n",
    "    \"\"\"\n",
    "    # TODO: Change the necessary parts to work correctly during evaluation (train=False)\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Set model to training mode if train=True, else evaluation mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()  # Set to evaluation mode\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    # Iterate over data\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero the parameter gradients only during training\n",
    "        if optimizer is not None:  # Check if optimizer is provided\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        with torch.set_grad_enabled(train):  # Enable gradients only during training\n",
    "            pred = model(xb)\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "            top1 = torch.argmax(pred, dim=1)\n",
    "            ncorrect = torch.sum(top1 == yb)\n",
    "\n",
    "            if train:  # Perform backpropagation and optimization only during training\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += ncorrect.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    epoch_acc /= len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7ITj_D4scJ-"
   },
   "source": [
    "Next we implement a method for fitting (training) our model. For many models early stopping can save a lot of training time. Your task is to add early stopping to the loop (based on validation accuracy). Early stopping usually means exiting the training loop if the validation accuracy hasn't improved for `patience` number of steps. Don't forget to save the best model parameters according to validation accuracy. You will need `copy.deepcopy` and the `state_dict` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1734447921618,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "q_pZaOQmscJ-"
   },
   "outputs": [],
   "source": [
    "def fit(model, optimizer, lr_scheduler, dataloaders, max_epochs, patience):\n",
    "    \"\"\"\n",
    "    Fit the given model on the dataset.\n",
    "\n",
    "    Args:\n",
    "        model: The model used for prediction\n",
    "        optimizer: Optimization algorithm for the model\n",
    "        lr_scheduler: Learning rate scheduler that improves training\n",
    "                      in late epochs with learning rate decay\n",
    "        dataloaders: Dataloaders for training and validation\n",
    "        max_epochs: Maximum number of epochs for training\n",
    "        patience: Number of epochs to wait with early stopping the\n",
    "                  training if validation loss has decreased\n",
    "\n",
    "    Returns:\n",
    "        Loss and accuracy in this epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    best_acc = 0\n",
    "    curr_patience = 0\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())  # Save the best model weights\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss, train_acc = run_epoch(model, optimizer, dataloaders['train'], train=True)\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train loss: {train_loss:.2e}, accuracy: {train_acc * 100:.2f}%\")\n",
    "\n",
    "        val_loss, val_acc = run_epoch(model, None, dataloaders['val'], train=False)\n",
    "        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, val loss: {val_loss:.2e}, accuracy: {val_acc * 100:.2f}%\")\n",
    "\n",
    "        # TODO: Add early stopping and save the best weights (in best_model_weights)\n",
    "        # Early stopping and saving best model weights\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())  # Save the current best weights\n",
    "            curr_patience = 0  # Reset patience counter\n",
    "            print(f\"Validation accuracy improved to {best_acc * 100:.2f}%, saving model...\")\n",
    "        else:\n",
    "            curr_patience += 1  # Increment patience counter\n",
    "            print(f\"No improvement for {curr_patience} epoch(s).\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if curr_patience >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(\"Training complete. Best validation accuracy: {:.2f}%\".format(best_acc * 100))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Paq2dS23scJ-"
   },
   "source": [
    "In most cases you should just use the Adam optimizer for training, because it works well out of the box. However, a well-tuned SGD (with momentum) will in most cases outperform Adam. And since the original paper gives us a well-tuned SGD we will just use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68096,
     "status": "ok",
     "timestamp": 1734452205779,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "B_nAyJcVscJ_",
    "outputId": "145be901-c1b3-4d2a-ec46-46f7484fbc5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/200, train loss: 1.71e-02, accuracy: 21.78%\n",
      "Epoch   1/200, val loss: 1.60e-02, accuracy: 27.98%\n",
      "Validation accuracy improved to 27.98%, saving model...\n",
      "Epoch   2/200, train loss: 1.25e-02, accuracy: 40.76%\n",
      "Epoch   2/200, val loss: 1.23e-02, accuracy: 45.52%\n",
      "Validation accuracy improved to 45.52%, saving model...\n",
      "Epoch   3/200, train loss: 1.02e-02, accuracy: 53.03%\n",
      "Epoch   3/200, val loss: 1.05e-02, accuracy: 53.84%\n",
      "Validation accuracy improved to 53.84%, saving model...\n",
      "Epoch   4/200, train loss: 8.14e-03, accuracy: 62.95%\n",
      "Epoch   4/200, val loss: 8.78e-03, accuracy: 62.38%\n",
      "Validation accuracy improved to 62.38%, saving model...\n",
      "Epoch   5/200, train loss: 6.81e-03, accuracy: 69.23%\n",
      "Epoch   5/200, val loss: 7.12e-03, accuracy: 69.80%\n",
      "Validation accuracy improved to 69.80%, saving model...\n",
      "Epoch   6/200, train loss: 6.03e-03, accuracy: 72.93%\n",
      "Epoch   6/200, val loss: 6.34e-03, accuracy: 73.44%\n",
      "Validation accuracy improved to 73.44%, saving model...\n",
      "Epoch   7/200, train loss: 5.38e-03, accuracy: 76.16%\n",
      "Epoch   7/200, val loss: 5.70e-03, accuracy: 77.08%\n",
      "Validation accuracy improved to 77.08%, saving model...\n",
      "Epoch   8/200, train loss: 5.02e-03, accuracy: 77.64%\n",
      "Epoch   8/200, val loss: 5.74e-03, accuracy: 76.78%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch   9/200, train loss: 4.66e-03, accuracy: 79.21%\n",
      "Epoch   9/200, val loss: 5.52e-03, accuracy: 76.88%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  10/200, train loss: 4.35e-03, accuracy: 80.58%\n",
      "Epoch  10/200, val loss: 4.97e-03, accuracy: 79.58%\n",
      "Validation accuracy improved to 79.58%, saving model...\n",
      "Epoch  11/200, train loss: 4.17e-03, accuracy: 81.18%\n",
      "Epoch  11/200, val loss: 4.71e-03, accuracy: 81.06%\n",
      "Validation accuracy improved to 81.06%, saving model...\n",
      "Epoch  12/200, train loss: 3.91e-03, accuracy: 82.76%\n",
      "Epoch  12/200, val loss: 4.91e-03, accuracy: 79.50%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  13/200, train loss: 3.79e-03, accuracy: 83.32%\n",
      "Epoch  13/200, val loss: 7.22e-03, accuracy: 73.18%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  14/200, train loss: 3.63e-03, accuracy: 83.81%\n",
      "Epoch  14/200, val loss: 4.96e-03, accuracy: 80.94%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  15/200, train loss: 3.48e-03, accuracy: 84.57%\n",
      "Epoch  15/200, val loss: 4.41e-03, accuracy: 81.70%\n",
      "Validation accuracy improved to 81.70%, saving model...\n",
      "Epoch  16/200, train loss: 3.36e-03, accuracy: 85.08%\n",
      "Epoch  16/200, val loss: 5.52e-03, accuracy: 78.14%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  17/200, train loss: 3.29e-03, accuracy: 85.44%\n",
      "Epoch  17/200, val loss: 4.01e-03, accuracy: 83.28%\n",
      "Validation accuracy improved to 83.28%, saving model...\n",
      "Epoch  18/200, train loss: 3.16e-03, accuracy: 85.94%\n",
      "Epoch  18/200, val loss: 4.78e-03, accuracy: 81.30%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  19/200, train loss: 3.09e-03, accuracy: 86.36%\n",
      "Epoch  19/200, val loss: 4.27e-03, accuracy: 82.76%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  20/200, train loss: 3.00e-03, accuracy: 86.53%\n",
      "Epoch  20/200, val loss: 3.97e-03, accuracy: 83.02%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  21/200, train loss: 2.90e-03, accuracy: 87.19%\n",
      "Epoch  21/200, val loss: 3.41e-03, accuracy: 85.84%\n",
      "Validation accuracy improved to 85.84%, saving model...\n",
      "Epoch  22/200, train loss: 2.90e-03, accuracy: 87.22%\n",
      "Epoch  22/200, val loss: 3.88e-03, accuracy: 84.02%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  23/200, train loss: 2.80e-03, accuracy: 87.47%\n",
      "Epoch  23/200, val loss: 4.38e-03, accuracy: 82.88%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  24/200, train loss: 2.67e-03, accuracy: 87.96%\n",
      "Epoch  24/200, val loss: 4.19e-03, accuracy: 83.16%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  25/200, train loss: 2.66e-03, accuracy: 88.15%\n",
      "Epoch  25/200, val loss: 4.94e-03, accuracy: 80.36%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  26/200, train loss: 2.58e-03, accuracy: 88.48%\n",
      "Epoch  26/200, val loss: 3.83e-03, accuracy: 85.04%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch  27/200, train loss: 2.58e-03, accuracy: 88.56%\n",
      "Epoch  27/200, val loss: 3.61e-03, accuracy: 85.26%\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch  28/200, train loss: 2.51e-03, accuracy: 88.80%\n",
      "Epoch  28/200, val loss: 3.65e-03, accuracy: 85.22%\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch  29/200, train loss: 2.47e-03, accuracy: 88.90%\n",
      "Epoch  29/200, val loss: 4.39e-03, accuracy: 83.54%\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch  30/200, train loss: 2.44e-03, accuracy: 89.10%\n",
      "Epoch  30/200, val loss: 3.52e-03, accuracy: 85.74%\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch  31/200, train loss: 2.35e-03, accuracy: 89.55%\n",
      "Epoch  31/200, val loss: 4.52e-03, accuracy: 81.82%\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch  32/200, train loss: 2.36e-03, accuracy: 89.46%\n",
      "Epoch  32/200, val loss: 4.17e-03, accuracy: 84.00%\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch  33/200, train loss: 2.31e-03, accuracy: 89.72%\n",
      "Epoch  33/200, val loss: 3.31e-03, accuracy: 86.68%\n",
      "Validation accuracy improved to 86.68%, saving model...\n",
      "Epoch  34/200, train loss: 2.23e-03, accuracy: 90.20%\n",
      "Epoch  34/200, val loss: 3.76e-03, accuracy: 85.28%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  35/200, train loss: 2.21e-03, accuracy: 90.11%\n",
      "Epoch  35/200, val loss: 4.12e-03, accuracy: 84.64%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  36/200, train loss: 2.23e-03, accuracy: 90.00%\n",
      "Epoch  36/200, val loss: 3.74e-03, accuracy: 85.68%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  37/200, train loss: 2.18e-03, accuracy: 90.16%\n",
      "Epoch  37/200, val loss: 4.85e-03, accuracy: 82.16%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  38/200, train loss: 2.17e-03, accuracy: 90.26%\n",
      "Epoch  38/200, val loss: 3.67e-03, accuracy: 86.00%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch  39/200, train loss: 2.13e-03, accuracy: 90.47%\n",
      "Epoch  39/200, val loss: 3.60e-03, accuracy: 85.14%\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch  40/200, train loss: 2.11e-03, accuracy: 90.62%\n",
      "Epoch  40/200, val loss: 3.94e-03, accuracy: 85.32%\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch  41/200, train loss: 2.09e-03, accuracy: 90.63%\n",
      "Epoch  41/200, val loss: 3.51e-03, accuracy: 86.38%\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch  42/200, train loss: 2.03e-03, accuracy: 90.89%\n",
      "Epoch  42/200, val loss: 4.01e-03, accuracy: 85.32%\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch  43/200, train loss: 2.10e-03, accuracy: 90.52%\n",
      "Epoch  43/200, val loss: 4.18e-03, accuracy: 84.22%\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch  44/200, train loss: 1.98e-03, accuracy: 91.01%\n",
      "Epoch  44/200, val loss: 4.74e-03, accuracy: 81.36%\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch  45/200, train loss: 2.00e-03, accuracy: 91.02%\n",
      "Epoch  45/200, val loss: 4.20e-03, accuracy: 84.32%\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch  46/200, train loss: 1.98e-03, accuracy: 91.05%\n",
      "Epoch  46/200, val loss: 3.70e-03, accuracy: 85.90%\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch  47/200, train loss: 1.97e-03, accuracy: 91.10%\n",
      "Epoch  47/200, val loss: 4.07e-03, accuracy: 85.08%\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch  48/200, train loss: 1.96e-03, accuracy: 91.23%\n",
      "Epoch  48/200, val loss: 3.89e-03, accuracy: 85.06%\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch  49/200, train loss: 1.93e-03, accuracy: 91.32%\n",
      "Epoch  49/200, val loss: 3.97e-03, accuracy: 84.96%\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch  50/200, train loss: 1.89e-03, accuracy: 91.59%\n",
      "Epoch  50/200, val loss: 4.51e-03, accuracy: 84.36%\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch  51/200, train loss: 1.87e-03, accuracy: 91.65%\n",
      "Epoch  51/200, val loss: 4.09e-03, accuracy: 85.32%\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch  52/200, train loss: 1.84e-03, accuracy: 91.70%\n",
      "Epoch  52/200, val loss: 3.98e-03, accuracy: 85.32%\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch  53/200, train loss: 1.89e-03, accuracy: 91.58%\n",
      "Epoch  53/200, val loss: 3.72e-03, accuracy: 85.86%\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch  54/200, train loss: 1.81e-03, accuracy: 91.84%\n",
      "Epoch  54/200, val loss: 3.78e-03, accuracy: 85.04%\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch  55/200, train loss: 1.84e-03, accuracy: 91.87%\n",
      "Epoch  55/200, val loss: 3.17e-03, accuracy: 87.32%\n",
      "Validation accuracy improved to 87.32%, saving model...\n",
      "Epoch  56/200, train loss: 1.76e-03, accuracy: 92.13%\n",
      "Epoch  56/200, val loss: 3.97e-03, accuracy: 84.98%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  57/200, train loss: 1.82e-03, accuracy: 91.78%\n",
      "Epoch  57/200, val loss: 4.13e-03, accuracy: 84.94%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  58/200, train loss: 1.80e-03, accuracy: 91.89%\n",
      "Epoch  58/200, val loss: 3.37e-03, accuracy: 86.96%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  59/200, train loss: 1.74e-03, accuracy: 92.22%\n",
      "Epoch  59/200, val loss: 3.40e-03, accuracy: 87.18%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  60/200, train loss: 1.72e-03, accuracy: 92.32%\n",
      "Epoch  60/200, val loss: 3.61e-03, accuracy: 87.12%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch  61/200, train loss: 1.76e-03, accuracy: 92.19%\n",
      "Epoch  61/200, val loss: 3.43e-03, accuracy: 87.42%\n",
      "Validation accuracy improved to 87.42%, saving model...\n",
      "Epoch  62/200, train loss: 1.73e-03, accuracy: 92.22%\n",
      "Epoch  62/200, val loss: 3.58e-03, accuracy: 86.82%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  63/200, train loss: 1.77e-03, accuracy: 92.03%\n",
      "Epoch  63/200, val loss: 3.61e-03, accuracy: 85.96%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  64/200, train loss: 1.73e-03, accuracy: 92.27%\n",
      "Epoch  64/200, val loss: 4.01e-03, accuracy: 85.96%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  65/200, train loss: 1.70e-03, accuracy: 92.30%\n",
      "Epoch  65/200, val loss: 4.22e-03, accuracy: 85.00%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  66/200, train loss: 1.70e-03, accuracy: 92.18%\n",
      "Epoch  66/200, val loss: 3.70e-03, accuracy: 86.70%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch  67/200, train loss: 1.68e-03, accuracy: 92.45%\n",
      "Epoch  67/200, val loss: 4.01e-03, accuracy: 86.04%\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch  68/200, train loss: 1.68e-03, accuracy: 92.52%\n",
      "Epoch  68/200, val loss: 3.53e-03, accuracy: 87.64%\n",
      "Validation accuracy improved to 87.64%, saving model...\n",
      "Epoch  69/200, train loss: 1.70e-03, accuracy: 92.29%\n",
      "Epoch  69/200, val loss: 3.44e-03, accuracy: 86.96%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  70/200, train loss: 1.66e-03, accuracy: 92.54%\n",
      "Epoch  70/200, val loss: 3.37e-03, accuracy: 87.58%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  71/200, train loss: 1.70e-03, accuracy: 92.30%\n",
      "Epoch  71/200, val loss: 4.06e-03, accuracy: 85.10%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  72/200, train loss: 1.64e-03, accuracy: 92.59%\n",
      "Epoch  72/200, val loss: 4.81e-03, accuracy: 84.48%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  73/200, train loss: 1.66e-03, accuracy: 92.48%\n",
      "Epoch  73/200, val loss: 3.23e-03, accuracy: 88.44%\n",
      "Validation accuracy improved to 88.44%, saving model...\n",
      "Epoch  74/200, train loss: 1.65e-03, accuracy: 92.64%\n",
      "Epoch  74/200, val loss: 3.13e-03, accuracy: 88.14%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch  75/200, train loss: 1.58e-03, accuracy: 92.84%\n",
      "Epoch  75/200, val loss: 4.30e-03, accuracy: 85.66%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch  76/200, train loss: 1.61e-03, accuracy: 92.78%\n",
      "Epoch  76/200, val loss: 3.30e-03, accuracy: 87.78%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch  77/200, train loss: 1.60e-03, accuracy: 92.86%\n",
      "Epoch  77/200, val loss: 3.28e-03, accuracy: 87.76%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch  78/200, train loss: 1.60e-03, accuracy: 92.79%\n",
      "Epoch  78/200, val loss: 4.24e-03, accuracy: 85.58%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch  79/200, train loss: 1.61e-03, accuracy: 92.71%\n",
      "Epoch  79/200, val loss: 3.30e-03, accuracy: 87.32%\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch  80/200, train loss: 1.62e-03, accuracy: 92.51%\n",
      "Epoch  80/200, val loss: 4.49e-03, accuracy: 84.60%\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch  81/200, train loss: 1.56e-03, accuracy: 92.92%\n",
      "Epoch  81/200, val loss: 3.56e-03, accuracy: 86.40%\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch  82/200, train loss: 1.60e-03, accuracy: 92.83%\n",
      "Epoch  82/200, val loss: 3.22e-03, accuracy: 88.06%\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch  83/200, train loss: 1.55e-03, accuracy: 93.07%\n",
      "Epoch  83/200, val loss: 3.56e-03, accuracy: 86.96%\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch  84/200, train loss: 1.55e-03, accuracy: 92.96%\n",
      "Epoch  84/200, val loss: 3.63e-03, accuracy: 87.52%\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch  85/200, train loss: 1.55e-03, accuracy: 92.96%\n",
      "Epoch  85/200, val loss: 3.87e-03, accuracy: 86.64%\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch  86/200, train loss: 1.52e-03, accuracy: 93.33%\n",
      "Epoch  86/200, val loss: 3.28e-03, accuracy: 87.76%\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch  87/200, train loss: 1.54e-03, accuracy: 93.11%\n",
      "Epoch  87/200, val loss: 5.69e-03, accuracy: 81.22%\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch  88/200, train loss: 1.57e-03, accuracy: 92.88%\n",
      "Epoch  88/200, val loss: 3.37e-03, accuracy: 87.52%\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch  89/200, train loss: 1.53e-03, accuracy: 93.06%\n",
      "Epoch  89/200, val loss: 4.36e-03, accuracy: 85.06%\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch  90/200, train loss: 1.53e-03, accuracy: 93.12%\n",
      "Epoch  90/200, val loss: 3.26e-03, accuracy: 88.08%\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch  91/200, train loss: 1.55e-03, accuracy: 93.14%\n",
      "Epoch  91/200, val loss: 4.06e-03, accuracy: 86.10%\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch  92/200, train loss: 1.50e-03, accuracy: 93.30%\n",
      "Epoch  92/200, val loss: 3.18e-03, accuracy: 88.32%\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch  93/200, train loss: 1.52e-03, accuracy: 93.18%\n",
      "Epoch  93/200, val loss: 4.05e-03, accuracy: 86.10%\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch  94/200, train loss: 1.50e-03, accuracy: 93.30%\n",
      "Epoch  94/200, val loss: 4.13e-03, accuracy: 85.58%\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch  95/200, train loss: 1.49e-03, accuracy: 93.27%\n",
      "Epoch  95/200, val loss: 3.93e-03, accuracy: 86.10%\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch  96/200, train loss: 1.48e-03, accuracy: 93.40%\n",
      "Epoch  96/200, val loss: 4.09e-03, accuracy: 85.64%\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch  97/200, train loss: 1.50e-03, accuracy: 93.31%\n",
      "Epoch  97/200, val loss: 4.06e-03, accuracy: 85.78%\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch  98/200, train loss: 1.53e-03, accuracy: 93.11%\n",
      "Epoch  98/200, val loss: 3.48e-03, accuracy: 87.60%\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch  99/200, train loss: 1.49e-03, accuracy: 93.18%\n",
      "Epoch  99/200, val loss: 3.95e-03, accuracy: 86.94%\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 100/200, train loss: 1.50e-03, accuracy: 93.33%\n",
      "Epoch 100/200, val loss: 3.15e-03, accuracy: 88.14%\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 101/200, train loss: 8.69e-04, accuracy: 96.21%\n",
      "Epoch 101/200, val loss: 2.09e-03, accuracy: 92.02%\n",
      "Validation accuracy improved to 92.02%, saving model...\n",
      "Epoch 102/200, train loss: 6.23e-04, accuracy: 97.42%\n",
      "Epoch 102/200, val loss: 2.09e-03, accuracy: 91.96%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 103/200, train loss: 5.19e-04, accuracy: 97.92%\n",
      "Epoch 103/200, val loss: 2.13e-03, accuracy: 91.98%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 104/200, train loss: 4.82e-04, accuracy: 98.04%\n",
      "Epoch 104/200, val loss: 2.22e-03, accuracy: 92.14%\n",
      "Validation accuracy improved to 92.14%, saving model...\n",
      "Epoch 105/200, train loss: 4.58e-04, accuracy: 98.05%\n",
      "Epoch 105/200, val loss: 2.22e-03, accuracy: 92.00%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 106/200, train loss: 4.04e-04, accuracy: 98.36%\n",
      "Epoch 106/200, val loss: 2.28e-03, accuracy: 92.06%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 107/200, train loss: 3.84e-04, accuracy: 98.48%\n",
      "Epoch 107/200, val loss: 2.34e-03, accuracy: 92.22%\n",
      "Validation accuracy improved to 92.22%, saving model...\n",
      "Epoch 108/200, train loss: 3.57e-04, accuracy: 98.56%\n",
      "Epoch 108/200, val loss: 2.30e-03, accuracy: 92.38%\n",
      "Validation accuracy improved to 92.38%, saving model...\n",
      "Epoch 109/200, train loss: 3.43e-04, accuracy: 98.58%\n",
      "Epoch 109/200, val loss: 2.30e-03, accuracy: 92.06%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 110/200, train loss: 3.05e-04, accuracy: 98.81%\n",
      "Epoch 110/200, val loss: 2.30e-03, accuracy: 92.42%\n",
      "Validation accuracy improved to 92.42%, saving model...\n",
      "Epoch 111/200, train loss: 2.99e-04, accuracy: 98.83%\n",
      "Epoch 111/200, val loss: 2.28e-03, accuracy: 92.20%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 112/200, train loss: 2.80e-04, accuracy: 98.90%\n",
      "Epoch 112/200, val loss: 2.37e-03, accuracy: 92.46%\n",
      "Validation accuracy improved to 92.46%, saving model...\n",
      "Epoch 113/200, train loss: 2.83e-04, accuracy: 98.82%\n",
      "Epoch 113/200, val loss: 2.39e-03, accuracy: 92.18%\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 114/200, train loss: 2.65e-04, accuracy: 98.92%\n",
      "Epoch 114/200, val loss: 2.49e-03, accuracy: 92.22%\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 115/200, train loss: 2.49e-04, accuracy: 99.03%\n",
      "Epoch 115/200, val loss: 2.49e-03, accuracy: 92.24%\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 116/200, train loss: 2.35e-04, accuracy: 99.09%\n",
      "Epoch 116/200, val loss: 2.50e-03, accuracy: 92.44%\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 117/200, train loss: 2.22e-04, accuracy: 99.15%\n",
      "Epoch 117/200, val loss: 2.50e-03, accuracy: 92.26%\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 118/200, train loss: 2.23e-04, accuracy: 99.10%\n",
      "Epoch 118/200, val loss: 2.54e-03, accuracy: 92.16%\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 119/200, train loss: 2.20e-04, accuracy: 99.09%\n",
      "Epoch 119/200, val loss: 2.51e-03, accuracy: 92.20%\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 120/200, train loss: 2.08e-04, accuracy: 99.22%\n",
      "Epoch 120/200, val loss: 2.53e-03, accuracy: 92.20%\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 121/200, train loss: 2.10e-04, accuracy: 99.17%\n",
      "Epoch 121/200, val loss: 2.55e-03, accuracy: 92.20%\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 122/200, train loss: 2.05e-04, accuracy: 99.16%\n",
      "Epoch 122/200, val loss: 2.49e-03, accuracy: 92.36%\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 123/200, train loss: 1.76e-04, accuracy: 99.33%\n",
      "Epoch 123/200, val loss: 2.69e-03, accuracy: 92.22%\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 124/200, train loss: 1.79e-04, accuracy: 99.32%\n",
      "Epoch 124/200, val loss: 2.58e-03, accuracy: 92.24%\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 125/200, train loss: 1.67e-04, accuracy: 99.37%\n",
      "Epoch 125/200, val loss: 2.70e-03, accuracy: 92.14%\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 126/200, train loss: 1.75e-04, accuracy: 99.31%\n",
      "Epoch 126/200, val loss: 2.74e-03, accuracy: 92.14%\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 127/200, train loss: 1.74e-04, accuracy: 99.29%\n",
      "Epoch 127/200, val loss: 2.78e-03, accuracy: 91.98%\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 128/200, train loss: 1.72e-04, accuracy: 99.30%\n",
      "Epoch 128/200, val loss: 2.67e-03, accuracy: 92.10%\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 129/200, train loss: 1.51e-04, accuracy: 99.44%\n",
      "Epoch 129/200, val loss: 2.65e-03, accuracy: 92.02%\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 130/200, train loss: 1.51e-04, accuracy: 99.44%\n",
      "Epoch 130/200, val loss: 2.71e-03, accuracy: 92.18%\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 131/200, train loss: 1.49e-04, accuracy: 99.42%\n",
      "Epoch 131/200, val loss: 2.60e-03, accuracy: 92.42%\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 132/200, train loss: 1.38e-04, accuracy: 99.48%\n",
      "Epoch 132/200, val loss: 2.60e-03, accuracy: 92.14%\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 133/200, train loss: 1.36e-04, accuracy: 99.48%\n",
      "Epoch 133/200, val loss: 2.77e-03, accuracy: 92.24%\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 134/200, train loss: 1.33e-04, accuracy: 99.53%\n",
      "Epoch 134/200, val loss: 2.84e-03, accuracy: 92.24%\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 135/200, train loss: 1.36e-04, accuracy: 99.45%\n",
      "Epoch 135/200, val loss: 2.65e-03, accuracy: 92.34%\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 136/200, train loss: 1.27e-04, accuracy: 99.56%\n",
      "Epoch 136/200, val loss: 2.81e-03, accuracy: 92.20%\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 137/200, train loss: 1.32e-04, accuracy: 99.47%\n",
      "Epoch 137/200, val loss: 2.79e-03, accuracy: 92.10%\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 138/200, train loss: 1.35e-04, accuracy: 99.48%\n",
      "Epoch 138/200, val loss: 2.71e-03, accuracy: 91.92%\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 139/200, train loss: 1.25e-04, accuracy: 99.55%\n",
      "Epoch 139/200, val loss: 2.75e-03, accuracy: 92.30%\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 140/200, train loss: 1.33e-04, accuracy: 99.47%\n",
      "Epoch 140/200, val loss: 2.82e-03, accuracy: 92.10%\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 141/200, train loss: 1.25e-04, accuracy: 99.53%\n",
      "Epoch 141/200, val loss: 2.76e-03, accuracy: 92.24%\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 142/200, train loss: 1.27e-04, accuracy: 99.54%\n",
      "Epoch 142/200, val loss: 2.87e-03, accuracy: 92.04%\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 143/200, train loss: 1.15e-04, accuracy: 99.60%\n",
      "Epoch 143/200, val loss: 2.92e-03, accuracy: 92.12%\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 144/200, train loss: 1.16e-04, accuracy: 99.55%\n",
      "Epoch 144/200, val loss: 3.00e-03, accuracy: 92.04%\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 145/200, train loss: 1.15e-04, accuracy: 99.55%\n",
      "Epoch 145/200, val loss: 2.85e-03, accuracy: 92.38%\n",
      "No improvement for 33 epoch(s).\n",
      "Epoch 146/200, train loss: 1.10e-04, accuracy: 99.59%\n",
      "Epoch 146/200, val loss: 2.84e-03, accuracy: 92.16%\n",
      "No improvement for 34 epoch(s).\n",
      "Epoch 147/200, train loss: 1.04e-04, accuracy: 99.63%\n",
      "Epoch 147/200, val loss: 2.92e-03, accuracy: 92.16%\n",
      "No improvement for 35 epoch(s).\n",
      "Epoch 148/200, train loss: 1.04e-04, accuracy: 99.65%\n",
      "Epoch 148/200, val loss: 3.01e-03, accuracy: 91.98%\n",
      "No improvement for 36 epoch(s).\n",
      "Epoch 149/200, train loss: 1.01e-04, accuracy: 99.65%\n",
      "Epoch 149/200, val loss: 3.01e-03, accuracy: 91.96%\n",
      "No improvement for 37 epoch(s).\n",
      "Epoch 150/200, train loss: 1.07e-04, accuracy: 99.59%\n",
      "Epoch 150/200, val loss: 2.95e-03, accuracy: 92.26%\n",
      "No improvement for 38 epoch(s).\n",
      "Epoch 151/200, train loss: 9.30e-05, accuracy: 99.70%\n",
      "Epoch 151/200, val loss: 2.92e-03, accuracy: 92.18%\n",
      "No improvement for 39 epoch(s).\n",
      "Epoch 152/200, train loss: 8.49e-05, accuracy: 99.70%\n",
      "Epoch 152/200, val loss: 2.85e-03, accuracy: 92.30%\n",
      "No improvement for 40 epoch(s).\n",
      "Epoch 153/200, train loss: 9.17e-05, accuracy: 99.68%\n",
      "Epoch 153/200, val loss: 2.84e-03, accuracy: 92.24%\n",
      "No improvement for 41 epoch(s).\n",
      "Epoch 154/200, train loss: 7.96e-05, accuracy: 99.74%\n",
      "Epoch 154/200, val loss: 2.85e-03, accuracy: 92.12%\n",
      "No improvement for 42 epoch(s).\n",
      "Epoch 155/200, train loss: 7.78e-05, accuracy: 99.76%\n",
      "Epoch 155/200, val loss: 2.85e-03, accuracy: 92.30%\n",
      "No improvement for 43 epoch(s).\n",
      "Epoch 156/200, train loss: 7.59e-05, accuracy: 99.76%\n",
      "Epoch 156/200, val loss: 2.86e-03, accuracy: 92.34%\n",
      "No improvement for 44 epoch(s).\n",
      "Epoch 157/200, train loss: 7.99e-05, accuracy: 99.76%\n",
      "Epoch 157/200, val loss: 2.89e-03, accuracy: 92.10%\n",
      "No improvement for 45 epoch(s).\n",
      "Epoch 158/200, train loss: 7.48e-05, accuracy: 99.78%\n",
      "Epoch 158/200, val loss: 2.85e-03, accuracy: 92.20%\n",
      "No improvement for 46 epoch(s).\n",
      "Epoch 159/200, train loss: 7.33e-05, accuracy: 99.77%\n",
      "Epoch 159/200, val loss: 2.88e-03, accuracy: 92.22%\n",
      "No improvement for 47 epoch(s).\n",
      "Epoch 160/200, train loss: 6.96e-05, accuracy: 99.81%\n",
      "Epoch 160/200, val loss: 2.87e-03, accuracy: 92.20%\n",
      "No improvement for 48 epoch(s).\n",
      "Epoch 161/200, train loss: 6.91e-05, accuracy: 99.78%\n",
      "Epoch 161/200, val loss: 2.87e-03, accuracy: 92.12%\n",
      "No improvement for 49 epoch(s).\n",
      "Epoch 162/200, train loss: 7.41e-05, accuracy: 99.79%\n",
      "Epoch 162/200, val loss: 2.88e-03, accuracy: 92.26%\n",
      "No improvement for 50 epoch(s).\n",
      "Early stopping triggered after 162 epochs.\n",
      "Training complete. Best validation accuracy: 92.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ResidualStack(\n",
       "      (blocks): ModuleList(\n",
       "        (0-4): 5 x ResidualBlock(\n",
       "          (skip): Sequential()\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualStack(\n",
       "      (blocks): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (skip): Lambda()\n",
       "          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1-4): 4 x ResidualBlock(\n",
       "          (skip): Sequential()\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualStack(\n",
       "      (blocks): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (skip): Lambda()\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1-4): 4 x ResidualBlock(\n",
       "          (skip): Sequential()\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (7): Lambda()\n",
       "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "# Fit model\n",
    "fit(resnet, optimizer, lr_scheduler, dataloaders, max_epochs=200, patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUuW_Y0bscJ_"
   },
   "source": [
    "Once the model is trained we run it on the test set to obtain our final accuracy.\n",
    "Note that we can only look at the test set once, everything else would lead to overfitting. So you _must_ ignore the test set while developing your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3117,
     "status": "ok",
     "timestamp": 1734452255096,
     "user": {
      "displayName": "Dany ang Feng",
      "userId": "16989503345906558610"
     },
     "user_tz": -60
    },
    "id": "S5Ping_QscJ_",
    "outputId": "306f9d80-d58e-4ca8-a294-327df6237117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.5e-03, accuracy: 91.65%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = run_epoch(resnet, None, dataloaders['test'], train=False)\n",
    "print(f\"Test loss: {test_loss:.1e}, accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzZGfVMtscJ_"
   },
   "source": [
    "That's almost what was reported in the paper (92.49%) and we didn't even train on the full training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQV8rlfIscJ_"
   },
   "source": [
    "# Optional task: Squeeze out all the juice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yube_m4scJ_"
   },
   "source": [
    "Can you do even better? Have a look at [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/) and some state-of-the-art architectures such as [EfficientNet architecture](https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html). Play around with the possibilities PyTorch offers you and see how close you can get to the [state of the art on CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
